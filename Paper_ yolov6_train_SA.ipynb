{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"EMtOceuDvw7b"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20088,"status":"ok","timestamp":1677643870118,"user":{"displayName":"shradha agarwal","userId":"13154026413399341008"},"user_tz":300},"id":"bu1cJmZ67tL2","outputId":"c7564d27-a122-4eb1-9f1d-f30df10ab325"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}],"source":["from google.colab import drive   \n","drive.mount('/content/drive/')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2cscvpx78Vr4"},"outputs":[],"source":["import os\n","os.chdir('drive/MyDrive/YOLO/yolov6')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4957,"status":"ok","timestamp":1677373037799,"user":{"displayName":"shradha agarwal","userId":"13154026413399341008"},"user_tz":300},"id":"r5jG4li38s1S","outputId":"d9d2c3ab-39eb-47f0-aae9-004b061a9dcc"},"outputs":[{"name":"stdout","output_type":"stream","text":["Cloning into 'YOLOv6'...\n","remote: Enumerating objects: 2893, done.\u001b[K\n","remote: Counting objects: 100% (131/131), done.\u001b[K\n","remote: Compressing objects: 100% (85/85), done.\u001b[K\n","remote: Total 2893 (delta 60), reused 101 (delta 46), pack-reused 2762\u001b[K\n","Receiving objects: 100% (2893/2893), 44.05 MiB | 17.89 MiB/s, done.\n","Resolving deltas: 100% (1621/1621), done.\n","Updating files: 100% (173/173), done.\n"]}],"source":["!git clone https://github.com/meituan/YOLOv6.git"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":281,"status":"ok","timestamp":1677643878476,"user":{"displayName":"shradha agarwal","userId":"13154026413399341008"},"user_tz":300},"id":"BsDSr_St8v3U","outputId":"b0ad1beb-7011-4caf-a8ac-a167bedf4d80"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/YOLO/yolov6/YOLOv6\n"]}],"source":["%cd YOLOv6"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":278,"status":"ok","timestamp":1677643880394,"user":{"displayName":"shradha agarwal","userId":"13154026413399341008"},"user_tz":300},"id":"Nw8zAzXhF5Jy","outputId":"3aa73462-3a50-48e5-8c9c-9ecf908102e9"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[0m\u001b[01;34massets\u001b[0m/   \u001b[01;34mdeploy\u001b[0m/     inference.ipynb  README.md         \u001b[01;34mtools\u001b[0m/\n","\u001b[01;34mconfigs\u001b[0m/  \u001b[01;34mdocs\u001b[0m/       LICENSE          requirements.txt  turtorial.ipynb\n","\u001b[01;34mdata\u001b[0m/     hubconf.py  README_cn.md     \u001b[01;34mruns\u001b[0m/             \u001b[01;34myolov6\u001b[0m/\n"]}],"source":["ls"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25073,"status":"ok","timestamp":1677643911191,"user":{"displayName":"shradha agarwal","userId":"13154026413399341008"},"user_tz":300},"id":"W_SKyyn2-S4z","outputId":"e68e4e1f-4891-4a57-b80d-83664e3b840a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 4)) (1.13.1+cu116)\n","Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 5)) (0.14.1+cu116)\n","Collecting numpy>=1.24.0\n","  Downloading numpy-1.24.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m74.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: opencv-python>=4.1.2 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 7)) (4.6.0.66)\n","Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 8)) (6.0)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 9)) (1.7.3)\n","Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 10)) (4.64.1)\n","Collecting addict>=2.4.0\n","  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n","Requirement already satisfied: tensorboard>=2.7.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 12)) (2.11.2)\n","Requirement already satisfied: pycocotools>=2.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 13)) (2.0.6)\n","Collecting onnx>=1.10.0\n","  Downloading onnx-1.13.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m87.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting onnx-simplifier>=0.3.6\n","  Downloading onnx_simplifier-0.4.17-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m91.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting thop\n","  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.8.0->-r requirements.txt (line 4)) (4.5.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchvision>=0.9.0->-r requirements.txt (line 5)) (2.25.1)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision>=0.9.0->-r requirements.txt (line 5)) (8.4.0)\n","Collecting scipy>=1.4.1\n","  Downloading scipy-1.10.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.5/34.5 MB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.7.0->-r requirements.txt (line 12)) (0.38.4)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.7.0->-r requirements.txt (line 12)) (57.4.0)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.7.0->-r requirements.txt (line 12)) (1.8.1)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.7.0->-r requirements.txt (line 12)) (1.51.3)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.7.0->-r requirements.txt (line 12)) (0.6.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.7.0->-r requirements.txt (line 12)) (3.4.1)\n","Requirement already satisfied: protobuf<4,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.7.0->-r requirements.txt (line 12)) (3.19.6)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.7.0->-r requirements.txt (line 12)) (2.2.3)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.7.0->-r requirements.txt (line 12)) (0.4.6)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.7.0->-r requirements.txt (line 12)) (2.16.1)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.7.0->-r requirements.txt (line 12)) (1.4.0)\n","Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.8/dist-packages (from pycocotools>=2.0->-r requirements.txt (line 13)) (3.5.3)\n","Collecting protobuf<4,>=3.9.2\n","  Downloading protobuf-3.20.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m75.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting rich\n","  Downloading rich-13.3.1-py3-none-any.whl (239 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.0/239.0 KB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.7.0->-r requirements.txt (line 12)) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.7.0->-r requirements.txt (line 12)) (4.9)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.7.0->-r requirements.txt (line 12)) (1.15.0)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.7.0->-r requirements.txt (line 12)) (5.3.0)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.7.0->-r requirements.txt (line 12)) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard>=2.7.0->-r requirements.txt (line 12)) (6.0.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0->-r requirements.txt (line 13)) (1.4.4)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0->-r requirements.txt (line 13)) (4.38.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0->-r requirements.txt (line 13)) (23.0)\n","Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0->-r requirements.txt (line 13)) (3.0.9)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0->-r requirements.txt (line 13)) (2.8.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0->-r requirements.txt (line 13)) (0.11.0)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision>=0.9.0->-r requirements.txt (line 5)) (4.0.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision>=0.9.0->-r requirements.txt (line 5)) (2022.12.7)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision>=0.9.0->-r requirements.txt (line 5)) (1.26.14)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision>=0.9.0->-r requirements.txt (line 5)) (2.10)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.8/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.7.0->-r requirements.txt (line 12)) (2.1.2)\n","Collecting markdown-it-py<3.0.0,>=2.1.0\n","  Downloading markdown_it_py-2.2.0-py3-none-any.whl (84 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.5/84.5 KB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pygments<3.0.0,>=2.14.0\n","  Downloading Pygments-2.14.0-py3-none-any.whl (1.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m62.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.7.0->-r requirements.txt (line 12)) (3.15.0)\n","Collecting mdurl~=0.1\n","  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.7.0->-r requirements.txt (line 12)) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.7.0->-r requirements.txt (line 12)) (3.2.2)\n","Installing collected packages: addict, pygments, protobuf, numpy, mdurl, thop, scipy, onnx, markdown-it-py, rich, onnx-simplifier\n","  Attempting uninstall: pygments\n","    Found existing installation: Pygments 2.6.1\n","    Uninstalling Pygments-2.6.1:\n","      Successfully uninstalled Pygments-2.6.1\n","  Attempting uninstall: protobuf\n","    Found existing installation: protobuf 3.19.6\n","    Uninstalling protobuf-3.19.6:\n","      Successfully uninstalled protobuf-3.19.6\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.22.4\n","    Uninstalling numpy-1.22.4:\n","      Successfully uninstalled numpy-1.22.4\n","  Attempting uninstall: scipy\n","    Found existing installation: scipy 1.7.3\n","    Uninstalling scipy-1.7.3:\n","      Successfully uninstalled scipy-1.7.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","ipython 7.9.0 requires jedi>=0.10, which is not installed.\n","tensorflow 2.11.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 3.20.3 which is incompatible.\n","numba 0.56.4 requires numpy<1.24,>=1.18, but you have numpy 1.24.2 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed addict-2.4.0 markdown-it-py-2.2.0 mdurl-0.1.2 numpy-1.24.2 onnx-1.13.1 onnx-simplifier-0.4.17 protobuf-3.20.3 pygments-2.14.0 rich-13.3.1 scipy-1.10.1 thop-0.1.1.post2209072238\n"]}],"source":["! pip install -r requirements.txt"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1315,"status":"ok","timestamp":1677643915840,"user":{"displayName":"shradha agarwal","userId":"13154026413399341008"},"user_tz":300},"id":"pKG_DUGxDmq3","outputId":"1fdd4899-537d-4a05-859d-ef9c51554a2d"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[0m\u001b[01;34massets\u001b[0m/   \u001b[01;34mdeploy\u001b[0m/     inference.ipynb  README.md         \u001b[01;34mtools\u001b[0m/\n","\u001b[01;34mconfigs\u001b[0m/  \u001b[01;34mdocs\u001b[0m/       LICENSE          requirements.txt  turtorial.ipynb\n","\u001b[01;34mdata\u001b[0m/     hubconf.py  README_cn.md     \u001b[01;34mruns\u001b[0m/             \u001b[01;34myolov6\u001b[0m/\n"]}],"source":["ls"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"W-N7ZgGIjihr","outputId":"1fddd137-a2df-4e4b-8c26-fa0fa0cae6b9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Using 1 GPU for training... \n","training args are: Namespace(batch_size=64, calib=False, check_images=False, check_labels=False, conf_file='configs/yolov6s.py', data_path='data/dataset.yaml', device='0', dist_url='env://', distill=False, distill_feat=False, epochs=4000, eval_final_only=False, eval_interval=20, gpu_count=0, heavy_eval_range=50, img_size=608, local_rank=-1, name='exp', output_dir='./runs/train', quant=False, rank=-1, resume=False, save_ckpt_on_last_n_epoch=-1, save_dir='runs/train/exp1', stop_aug_last_n_epoch=15, teacher_model_path=None, temperature=20, workers=8, world_size=1, write_trainbatch_tb=False)\n","\n","Train: Final numbers of valid images: 231/ labels: 231. \n","3.5s for dataset initialization.\n","Convert to COCO format\n","100% 23/23 [00:00<00:00, 20369.30it/s]\n","Convert to COCO format finished. Resutls saved in ../custom_dataset/annotations/instances_test.json\n","Val: Final numbers of valid images: 23/ labels: 23. \n","2.5s for dataset initialization.\n","Model: Model(\n","  (backbone): EfficientRep(\n","    (stem): RepVGGBlock(\n","      (nonlinearity): ReLU(inplace=True)\n","      (se): Identity()\n","      (rbr_dense): Sequential(\n","        (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","      )\n","      (rbr_1x1): Sequential(\n","        (conv): Conv2d(3, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (ERBlock_2): Sequential(\n","      (0): RepVGGBlock(\n","        (nonlinearity): ReLU(inplace=True)\n","        (se): Identity()\n","        (rbr_dense): Sequential(\n","          (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        )\n","        (rbr_1x1): Sequential(\n","          (conv): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): RepBlock(\n","        (conv1): RepVGGBlock(\n","          (nonlinearity): ReLU(inplace=True)\n","          (se): Identity()\n","          (rbr_identity): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          (rbr_dense): Sequential(\n","            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","          (rbr_1x1): Sequential(\n","            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (block): Sequential(\n","          (0): RepVGGBlock(\n","            (nonlinearity): ReLU(inplace=True)\n","            (se): Identity()\n","            (rbr_identity): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (rbr_dense): Sequential(\n","              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            )\n","            (rbr_1x1): Sequential(\n","              (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            )\n","          )\n","        )\n","      )\n","    )\n","    (ERBlock_3): Sequential(\n","      (0): RepVGGBlock(\n","        (nonlinearity): ReLU(inplace=True)\n","        (se): Identity()\n","        (rbr_dense): Sequential(\n","          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        )\n","        (rbr_1x1): Sequential(\n","          (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): RepBlock(\n","        (conv1): RepVGGBlock(\n","          (nonlinearity): ReLU(inplace=True)\n","          (se): Identity()\n","          (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          (rbr_dense): Sequential(\n","            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","          (rbr_1x1): Sequential(\n","            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (block): Sequential(\n","          (0): RepVGGBlock(\n","            (nonlinearity): ReLU(inplace=True)\n","            (se): Identity()\n","            (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (rbr_dense): Sequential(\n","              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            )\n","            (rbr_1x1): Sequential(\n","              (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            )\n","          )\n","          (1): RepVGGBlock(\n","            (nonlinearity): ReLU(inplace=True)\n","            (se): Identity()\n","            (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (rbr_dense): Sequential(\n","              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            )\n","            (rbr_1x1): Sequential(\n","              (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            )\n","          )\n","          (2): RepVGGBlock(\n","            (nonlinearity): ReLU(inplace=True)\n","            (se): Identity()\n","            (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (rbr_dense): Sequential(\n","              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            )\n","            (rbr_1x1): Sequential(\n","              (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            )\n","          )\n","        )\n","      )\n","    )\n","    (ERBlock_4): Sequential(\n","      (0): RepVGGBlock(\n","        (nonlinearity): ReLU(inplace=True)\n","        (se): Identity()\n","        (rbr_dense): Sequential(\n","          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        )\n","        (rbr_1x1): Sequential(\n","          (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): RepBlock(\n","        (conv1): RepVGGBlock(\n","          (nonlinearity): ReLU(inplace=True)\n","          (se): Identity()\n","          (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          (rbr_dense): Sequential(\n","            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","          (rbr_1x1): Sequential(\n","            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (block): Sequential(\n","          (0): RepVGGBlock(\n","            (nonlinearity): ReLU(inplace=True)\n","            (se): Identity()\n","            (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (rbr_dense): Sequential(\n","              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            )\n","            (rbr_1x1): Sequential(\n","              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            )\n","          )\n","          (1): RepVGGBlock(\n","            (nonlinearity): ReLU(inplace=True)\n","            (se): Identity()\n","            (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (rbr_dense): Sequential(\n","              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            )\n","            (rbr_1x1): Sequential(\n","              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            )\n","          )\n","          (2): RepVGGBlock(\n","            (nonlinearity): ReLU(inplace=True)\n","            (se): Identity()\n","            (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (rbr_dense): Sequential(\n","              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            )\n","            (rbr_1x1): Sequential(\n","              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            )\n","          )\n","          (3): RepVGGBlock(\n","            (nonlinearity): ReLU(inplace=True)\n","            (se): Identity()\n","            (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (rbr_dense): Sequential(\n","              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            )\n","            (rbr_1x1): Sequential(\n","              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            )\n","          )\n","          (4): RepVGGBlock(\n","            (nonlinearity): ReLU(inplace=True)\n","            (se): Identity()\n","            (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (rbr_dense): Sequential(\n","              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            )\n","            (rbr_1x1): Sequential(\n","              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            )\n","          )\n","        )\n","      )\n","    )\n","    (ERBlock_5): Sequential(\n","      (0): RepVGGBlock(\n","        (nonlinearity): ReLU(inplace=True)\n","        (se): Identity()\n","        (rbr_dense): Sequential(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","          (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        )\n","        (rbr_1x1): Sequential(\n","          (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): RepBlock(\n","        (conv1): RepVGGBlock(\n","          (nonlinearity): ReLU(inplace=True)\n","          (se): Identity()\n","          (rbr_identity): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          (rbr_dense): Sequential(\n","            (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","          (rbr_1x1): Sequential(\n","            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (block): Sequential(\n","          (0): RepVGGBlock(\n","            (nonlinearity): ReLU(inplace=True)\n","            (se): Identity()\n","            (rbr_identity): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (rbr_dense): Sequential(\n","              (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            )\n","            (rbr_1x1): Sequential(\n","              (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            )\n","          )\n","        )\n","      )\n","      (2): SimSPPF(\n","        (cv1): SimConv(\n","          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          (act): ReLU(inplace=True)\n","        )\n","        (cv2): SimConv(\n","          (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          (act): ReLU(inplace=True)\n","        )\n","        (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n","      )\n","    )\n","  )\n","  (neck): RepPANNeck(\n","    (Rep_p4): RepBlock(\n","      (conv1): RepVGGBlock(\n","        (nonlinearity): ReLU(inplace=True)\n","        (se): Identity()\n","        (rbr_dense): Sequential(\n","          (conv): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        )\n","        (rbr_1x1): Sequential(\n","          (conv): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (block): Sequential(\n","        (0): RepVGGBlock(\n","          (nonlinearity): ReLU(inplace=True)\n","          (se): Identity()\n","          (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          (rbr_dense): Sequential(\n","            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","          (rbr_1x1): Sequential(\n","            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (1): RepVGGBlock(\n","          (nonlinearity): ReLU(inplace=True)\n","          (se): Identity()\n","          (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          (rbr_dense): Sequential(\n","            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","          (rbr_1x1): Sequential(\n","            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (2): RepVGGBlock(\n","          (nonlinearity): ReLU(inplace=True)\n","          (se): Identity()\n","          (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          (rbr_dense): Sequential(\n","            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","          (rbr_1x1): Sequential(\n","            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","        )\n","      )\n","    )\n","    (Rep_p3): RepBlock(\n","      (conv1): RepVGGBlock(\n","        (nonlinearity): ReLU(inplace=True)\n","        (se): Identity()\n","        (rbr_dense): Sequential(\n","          (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        )\n","        (rbr_1x1): Sequential(\n","          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (block): Sequential(\n","        (0): RepVGGBlock(\n","          (nonlinearity): ReLU(inplace=True)\n","          (se): Identity()\n","          (rbr_identity): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          (rbr_dense): Sequential(\n","            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","          (rbr_1x1): Sequential(\n","            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (1): RepVGGBlock(\n","          (nonlinearity): ReLU(inplace=True)\n","          (se): Identity()\n","          (rbr_identity): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          (rbr_dense): Sequential(\n","            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","          (rbr_1x1): Sequential(\n","            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (2): RepVGGBlock(\n","          (nonlinearity): ReLU(inplace=True)\n","          (se): Identity()\n","          (rbr_identity): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          (rbr_dense): Sequential(\n","            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","          (rbr_1x1): Sequential(\n","            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","        )\n","      )\n","    )\n","    (Rep_n3): RepBlock(\n","      (conv1): RepVGGBlock(\n","        (nonlinearity): ReLU(inplace=True)\n","        (se): Identity()\n","        (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (rbr_dense): Sequential(\n","          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        )\n","        (rbr_1x1): Sequential(\n","          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (block): Sequential(\n","        (0): RepVGGBlock(\n","          (nonlinearity): ReLU(inplace=True)\n","          (se): Identity()\n","          (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          (rbr_dense): Sequential(\n","            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","          (rbr_1x1): Sequential(\n","            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (1): RepVGGBlock(\n","          (nonlinearity): ReLU(inplace=True)\n","          (se): Identity()\n","          (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          (rbr_dense): Sequential(\n","            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","          (rbr_1x1): Sequential(\n","            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (2): RepVGGBlock(\n","          (nonlinearity): ReLU(inplace=True)\n","          (se): Identity()\n","          (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          (rbr_dense): Sequential(\n","            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","          (rbr_1x1): Sequential(\n","            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","        )\n","      )\n","    )\n","    (Rep_n4): RepBlock(\n","      (conv1): RepVGGBlock(\n","        (nonlinearity): ReLU(inplace=True)\n","        (se): Identity()\n","        (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (rbr_dense): Sequential(\n","          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        )\n","        (rbr_1x1): Sequential(\n","          (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (block): Sequential(\n","        (0): RepVGGBlock(\n","          (nonlinearity): ReLU(inplace=True)\n","          (se): Identity()\n","          (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          (rbr_dense): Sequential(\n","            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","          (rbr_1x1): Sequential(\n","            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (1): RepVGGBlock(\n","          (nonlinearity): ReLU(inplace=True)\n","          (se): Identity()\n","          (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          (rbr_dense): Sequential(\n","            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","          (rbr_1x1): Sequential(\n","            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (2): RepVGGBlock(\n","          (nonlinearity): ReLU(inplace=True)\n","          (se): Identity()\n","          (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          (rbr_dense): Sequential(\n","            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","          (rbr_1x1): Sequential(\n","            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","        )\n","      )\n","    )\n","    (reduce_layer0): SimConv(\n","      (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","    )\n","    (upsample0): Transpose(\n","      (upsample_transpose): ConvTranspose2d(128, 128, kernel_size=(2, 2), stride=(2, 2))\n","    )\n","    (reduce_layer1): SimConv(\n","      (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","    )\n","    (upsample1): Transpose(\n","      (upsample_transpose): ConvTranspose2d(64, 64, kernel_size=(2, 2), stride=(2, 2))\n","    )\n","    (downsample2): SimConv(\n","      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","    )\n","    (downsample1): SimConv(\n","      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","    )\n","  )\n","  (detect): Detect(\n","    (proj_conv): Conv2d(17, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (stems): ModuleList(\n","      (0): Conv(\n","        (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): SiLU(inplace=True)\n","      )\n","      (1): Conv(\n","        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): SiLU(inplace=True)\n","      )\n","      (2): Conv(\n","        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): SiLU(inplace=True)\n","      )\n","    )\n","    (cls_convs): ModuleList(\n","      (0): Conv(\n","        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): SiLU(inplace=True)\n","      )\n","      (1): Conv(\n","        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): SiLU(inplace=True)\n","      )\n","      (2): Conv(\n","        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): SiLU(inplace=True)\n","      )\n","    )\n","    (reg_convs): ModuleList(\n","      (0): Conv(\n","        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): SiLU(inplace=True)\n","      )\n","      (1): Conv(\n","        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): SiLU(inplace=True)\n","      )\n","      (2): Conv(\n","        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): SiLU(inplace=True)\n","      )\n","    )\n","    (cls_preds): ModuleList(\n","      (0): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n","      (1): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n","      (2): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n","    )\n","    (reg_preds): ModuleList(\n","      (0): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n","      (1): Conv2d(128, 4, kernel_size=(1, 1), stride=(1, 1))\n","      (2): Conv2d(256, 4, kernel_size=(1, 1), stride=(1, 1))\n","    )\n","  )\n",")\n","2023-02-26 05:06:51.815661: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-02-26 05:06:53.699293: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.8/dist-packages/cv2/../../lib64:/usr/lib64-nvidia\n","2023-02-26 05:06:53.699417: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.8/dist-packages/cv2/../../lib64:/usr/lib64-nvidia\n","2023-02-26 05:06:53.699437: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n","Training start...\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","  0% 0/4 [00:00<?, ?it/s]/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n","  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n","    0/3999     2.084         0    0.9041: 100% 4/4 [00:16<00:00,  4.21s/it]\n","Inferencing model in train datasets.: 100% 1/1 [00:00<00:00,  2.67it/s]\n","\n","Evaluating speed.\n","\n","Evaluating mAP by pycocotools.\n","Epoch: 0 | mAP@0.5: 0.0 | mAP@0.50:0.95: 0.0\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","    1/3999     2.047         0    0.9676:  25% 1/4 [00:01<00:04,  1.46s/it]OOM RuntimeError is raised due to the huge memory cost during label assignment.                     CPU mode is applied in this batch. If you want to avoid this issue,                     try to reduce the batch size or image size.\n","------------CPU Mode for This Batch-------------\n","    1/3999     2.034         0    0.9911:  50% 2/4 [00:16<00:18,  9.19s/it]OOM RuntimeError is raised due to the huge memory cost during label assignment.                     CPU mode is applied in this batch. If you want to avoid this issue,                     try to reduce the batch size or image size.\n","------------CPU Mode for This Batch-------------\n","    1/3999     2.002         0     1.038: 100% 4/4 [00:28<00:00,  7.02s/it]\n","\n","     Epoch  iou_loss  dfl_loss  cls_loss\n","  0% 0/4 [00:00<?, ?it/s]OOM RuntimeError is raised due to the huge memory cost during label assignment.                     CPU mode is applied in this batch. If you want to avoid this issue,                     try to reduce the batch size or image size.\n","------------CPU Mode for This Batch-------------\n","    2/3999     1.858         0     1.255: 100% 4/4 [00:15<00:00,  3.93s/it]\n"]}],"source":["!python tools/train.py --img-size 608 --batch 32 --epoch 4000 --conf configs/yolov6s.py --data data/dataset.yaml --device 0 #Display is wrong;  The results were ran at 1000 epochs and then at 1000 epochs, with batch size 32 saved at exp 2 and exp 3 "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":39837,"status":"ok","timestamp":1677644048529,"user":{"displayName":"shradha agarwal","userId":"13154026413399341008"},"user_tz":300},"id":"H-NWOWbdQ4ar","outputId":"fa7cc666-72b2-429d-f0dc-548e26e43093"},"outputs":[{"output_type":"stream","name":"stdout","text":["Namespace(batch_size=16, conf_thres=0.03, config_file='', data='data/dataset.yaml', device='0', do_coco_metric=True, do_pr_metric=True, eval_config_file='./configs/experiment/eval_640_repro.py', force_no_pad=False, half=False, img_size=640, iou_thres=0.65, letterbox_return_int=False, name='exp', not_infer_on_rect=False, plot_confusion_matrix=False, plot_curve=True, reproduce_640_eval=False, save_dir='runs/val/', scale_exact=False, task='val', test_load_size=640, verbose=False, weights='runs/train/exp2/weights/last_ckpt.pt')\n","Loading checkpoint from runs/train/exp2/weights/last_ckpt.pt\n","\n","Fusing model...\n","/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n","  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n","Switch model to deploy modality.\n","Model Summary: Params: 18.50M, Gflops: 45.17\n","Val: Checking formats of labels with 2 process(es): \n","11 label(s) found, 0 label(s) missing, 0 label(s) empty, 0 invalid label files: 100% 11/11 [00:01<00:00,  8.68it/s]\n","Convert to COCO format\n","100% 11/11 [00:00<00:00, 25322.36it/s]\n","Convert to COCO format finished. Resutls saved in ../custom_dataset/annotations/instances_valid.json\n","Val: Final numbers of valid images: 11/ labels: 11. \n","2.4s for dataset initialization.\n","Inferencing model in val datasets.: 100% 1/1 [00:04<00:00,  4.03s/it]\n","IOU 50 best mF1 thershold near 0.629.\n","Class                 Images      Labels     P@.5iou     R@.5iou    F1@.5iou      mAP@.5  mAP@.5:.95\n","all                       11         186        0.93        0.93        0.93       0.946       0.535\n","\n","Evaluating speed.\n","Average pre-process time: 0.21 ms\n","Average inference time: 17.54 ms\n","Average NMS time: 5.83 ms\n","\n","Evaluating mAP by pycocotools.\n","Saving runs/val/exp2/predictions.json...\n","loading annotations into memory...\n","Done (t=0.00s)\n","creating index...\n","index created!\n","Loading and preparing results...\n","DONE (t=0.07s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=0.24s).\n","Accumulating evaluation results...\n","DONE (t=0.02s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.529\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.935\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.536\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.221\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.493\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.595\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.039\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.389\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.605\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.450\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.570\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.665\n","Results saved to runs/val/exp2\n"]}],"source":["#11 images (or valid image folder)-last_ckpt\n","!python tools/eval.py --save_dir runs/val/ --data data/dataset.yaml  --batch 16 --weights runs/train/exp2/weights/last_ckpt.pt --do_pr_metric True --task val"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12515,"status":"ok","timestamp":1677644180870,"user":{"displayName":"shradha agarwal","userId":"13154026413399341008"},"user_tz":300},"id":"f6TEu0dvzmTB","outputId":"09553814-36b0-40fa-ce79-1a15e059e5fb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Namespace(batch_size=16, conf_thres=0.03, config_file='', data='data/dataset.yaml', device='0', do_coco_metric=True, do_pr_metric=True, eval_config_file='./configs/experiment/eval_640_repro.py', force_no_pad=False, half=False, img_size=640, iou_thres=0.65, letterbox_return_int=False, name='exp', not_infer_on_rect=False, plot_confusion_matrix=False, plot_curve=True, reproduce_640_eval=False, save_dir='runs/val/', scale_exact=False, task='val', test_load_size=640, verbose=False, weights='runs/train/exp2/weights/best_ckpt.pt')\n","Loading checkpoint from runs/train/exp2/weights/best_ckpt.pt\n","\n","Fusing model...\n","/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n","  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n","Switch model to deploy modality.\n","Model Summary: Params: 18.50M, Gflops: 45.17\n","Val: Checking formats of labels with 2 process(es): \n","11 label(s) found, 0 label(s) missing, 0 label(s) empty, 0 invalid label files: 100% 11/11 [00:00<00:00, 417.19it/s]\n","Convert to COCO format\n","100% 11/11 [00:00<00:00, 14341.73it/s]\n","Convert to COCO format finished. Resutls saved in ../custom_dataset/annotations/instances_valid.json\n","Val: Final numbers of valid images: 11/ labels: 11. \n","0.2s for dataset initialization.\n","Inferencing model in val datasets.: 100% 1/1 [00:02<00:00,  2.13s/it]\n","IOU 50 best mF1 thershold near 0.457.\n","Class                 Images      Labels     P@.5iou     R@.5iou    F1@.5iou      mAP@.5  mAP@.5:.95\n","all                       11         186       0.934       0.914       0.924       0.955       0.554\n","\n","Evaluating speed.\n","Average pre-process time: 0.22 ms\n","Average inference time: 19.47 ms\n","Average NMS time: 11.15 ms\n","\n","Evaluating mAP by pycocotools.\n","Saving runs/val/exp3/predictions.json...\n","loading annotations into memory...\n","Done (t=0.00s)\n","creating index...\n","index created!\n","Loading and preparing results...\n","DONE (t=0.08s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=0.24s).\n","Accumulating evaluation results...\n","DONE (t=0.01s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.544\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.940\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.562\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.052\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.506\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.618\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.044\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.399\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.634\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.250\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.604\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.693\n","Results saved to runs/val/exp3\n"]}],"source":["#11 images (or valid image folder)-best_ckpt\n","!python tools/eval.py --save_dir runs/val/ --data data/dataset.yaml  --batch 16 --weights runs/train/exp2/weights/best_ckpt.pt --do_pr_metric True --task val"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14931,"status":"ok","timestamp":1677644431331,"user":{"displayName":"shradha agarwal","userId":"13154026413399341008"},"user_tz":300},"id":"aFA_SkDDztM3","outputId":"8b878391-2e45-4747-a153-c9abaa5c8c64"},"outputs":[{"output_type":"stream","name":"stdout","text":["Namespace(batch_size=16, conf_thres=0.03, config_file='', data='data/dataset_test.yaml', device='0', do_coco_metric=True, do_pr_metric=True, eval_config_file='./configs/experiment/eval_640_repro.py', force_no_pad=False, half=False, img_size=640, iou_thres=0.65, letterbox_return_int=False, name='exp', not_infer_on_rect=False, plot_confusion_matrix=False, plot_curve=True, reproduce_640_eval=False, save_dir='runs/val/', scale_exact=False, task='val', test_load_size=640, verbose=False, weights='runs/train/exp3/weights/best_ckpt.pt')\n","Loading checkpoint from runs/train/exp3/weights/best_ckpt.pt\n","\n","Fusing model...\n","/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n","  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n","Switch model to deploy modality.\n","Model Summary: Params: 18.50M, Gflops: 45.17\n","Val: Checking formats of labels with 2 process(es): \n","23 label(s) found, 0 label(s) missing, 0 label(s) empty, 0 invalid label files: 100% 23/23 [00:00<00:00, 601.73it/s]\n","Convert to COCO format\n","100% 23/23 [00:00<00:00, 24250.63it/s]\n","Convert to COCO format finished. Resutls saved in ../custom_dataset/annotations/instances_test.json\n","Val: Final numbers of valid images: 23/ labels: 23. \n","0.2s for dataset initialization.\n","Inferencing model in val datasets.: 100% 2/2 [00:01<00:00,  1.03it/s]\n","IOU 50 best mF1 thershold near 0.557.\n","Class                 Images      Labels     P@.5iou     R@.5iou    F1@.5iou      mAP@.5  mAP@.5:.95\n","all                       23         357       0.918        0.91       0.914       0.921       0.489\n","\n","Evaluating speed.\n","Average pre-process time: 0.21 ms\n","Average inference time: 12.12 ms\n","Average NMS time: 3.65 ms\n","\n","Evaluating mAP by pycocotools.\n","Saving runs/val/exp6/predictions.json...\n","loading annotations into memory...\n","Done (t=0.00s)\n","creating index...\n","index created!\n","Loading and preparing results...\n","DONE (t=0.04s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=1.07s).\n","Accumulating evaluation results...\n","DONE (t=0.04s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.486\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.913\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.474\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.049\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.471\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.548\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.042\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.395\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.595\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.400\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.572\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.658\n","Results saved to runs/val/exp6\n"]}],"source":["#23  images (or test image folder)-best_ckpt   #the value below is for exp3 or 2000 epochs\n","!python tools/eval.py --save_dir runs/val/ --data data/dataset_test.yaml  --batch 16 --weights runs/train/exp3/weights/best_ckpt.pt --do_pr_metric True --task val"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10149,"status":"ok","timestamp":1677644993787,"user":{"displayName":"shradha agarwal","userId":"13154026413399341008"},"user_tz":300},"id":"W7izO9xWQh_Y","outputId":"2378adf0-d5d9-4739-ab14-46eb4b23522f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Namespace(agnostic_nms=False, classes=None, conf_thres=0.4, device='0', half=False, hide_conf=False, hide_labels=False, img_size=[640, 640], iou_thres=0.45, max_det=1000, name='exp', not_save_img=False, project='runs/inference', save_dir=None, save_txt=False, source='../custom_dataset/images/test', view_img=False, webcam=False, webcam_addr='0', weights='runs/train/exp3/weights/best_ckpt.pt', yaml='data/dataset_test.yaml')\n","Loading checkpoint from runs/train/exp3/weights/best_ckpt.pt\n","\n","Fusing model...\n","Switch model to deploy modality.\n","/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n","  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n","100% 23/23 [00:01<00:00, 12.17it/s]\n","Results saved to runs/inference/exp\n"]}],"source":["!python tools/infer.py --weights runs/train/exp3/weights/best_ckpt.pt --source ../custom_dataset/images/test  --yaml data/dataset_test.yaml --device 0 #infer.py give you the images from test folder "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7038,"status":"ok","timestamp":1677645015347,"user":{"displayName":"shradha agarwal","userId":"13154026413399341008"},"user_tz":300},"id":"6AC0g3dsQe7l","outputId":"7f36b118-f4f9-40c9-adf3-69a460bc2cde"},"outputs":[{"output_type":"stream","name":"stdout","text":["Namespace(agnostic_nms=False, classes=None, conf_thres=0.4, device='0', half=False, hide_conf=False, hide_labels=False, img_size=[640, 640], iou_thres=0.45, max_det=1000, name='exp', not_save_img=False, project='runs/inference', save_dir=None, save_txt=False, source='../custom_dataset/images/valid', view_img=False, webcam=False, webcam_addr='0', weights='runs/train/exp3/weights/best_ckpt.pt', yaml='data/dataset.yaml')\n","Save directory already existed\n","Loading checkpoint from runs/train/exp3/weights/best_ckpt.pt\n","\n","Fusing model...\n","Switch model to deploy modality.\n","/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n","  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n","100% 11/11 [00:00<00:00, 17.82it/s]\n","Results saved to runs/inference/exp\n"]}],"source":["!python tools/infer.py --weights runs/train/exp3/weights/best_ckpt.pt --source ../custom_dataset/images/valid  --yaml data/dataset.yaml --device 0 #infer.py give you the images from val folder"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1qxZXHLy73ZwJGrJ6Gazzqhxmju8H9OQP","timestamp":1677370178114}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}